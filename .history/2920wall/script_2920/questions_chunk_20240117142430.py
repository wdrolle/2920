'''
    The `process_file` function takes a file path as input and processes the file to extract text. It
    then chunks the text into smaller parts and generates questions and answers for each chunk using a
    language model. The generated questions and answers are saved in a JSON file.
    
    :param response_text: 
        The `response_text` parameter is the text generated by the language model. It
        can be the generated question or answer
    
    :return: 
        The code generates a question and answer based on a
        given prompt, but the specific question and answer are not provided in the code.
'''

import os
import json
import re
import torch
import requests
import fitz  # PyMuPDF for PDF processing
import PyPDF2  # PyPDF2 for PDF processing
import docx  # python-docx for Word document processing
import pandas as pd  # Pandas for CSV and XLSX processing
from openpyxl import load_workbook  # openpyxl for XLSX processing
import markdown2  # Markdown to plain text conversion

# Constants for processing
MAX_QUESTIONS = 1
CHUNK_SIZE = 500

# Initialize GPU for text generation
torch.cuda.empty_cache()

def remove_prompt_from_response(response_text):
    # Use regex to remove "<s>***" pattern and everything following it
    response_text = re.sub(r'<s>.*', '', response_text).strip()
    # Remove "Question?..." if present
    response_text = re.sub(r"Question?.*", "", response_text).strip()
    response_text = response_text.replace('• ', '').strip()
    response_text = response_text.replace('•', '').strip()
    return response_text

def generate_question(prompt):
    instruction = f"<s>[INST] You are a Banking Compliance Consultant tasked with developing Banking Risk Assessments. Having an understanding of requirements to perform, consider this context, '{prompt}', create a question that is precisely related to the context. Do not indirectly create a question. Be specific to the context. Do not change names, or alter the context when creating the question. Keep the question concise and short. Do not create random questions. [/INST]"
    payload = {"context": instruction}
    try:
        response = requests.post("http://localhost:8000/generate/", json=payload)
        if response.status_code == 200:
            question_text = response.json()[0]['generated_text']
            return question_text.replace(instruction, "").strip()
        else:
            return "Error in LLM response"
    except requests.RequestException as e:
        return str(e)

def generate_answer(prompt, question):
    instruction = f"<s>[INST] You are a Banking Compliance Consultant tasked with developing Banking Risk Assessments. Having an understanding of requirements to perform, given the context '{prompt}', answer this question directly from the context: '{question}'. Provide the answer only, with no additional explanation, text, or modification. Only include the answer. make sure that your response is a whole sentence, Do not provide incomplete sentences.[/INST]"
    payload = {"context": instruction}
    try:
        response = requests.post("http://localhost:8000/generate/", json=payload)
        if response.status_code == 200:
            answer_text = response.json()[0]['generated_text']
            return answer_text.replace(instruction, "").strip()
        else:
            return "Error in LLM response"
    except requests.RequestException as e:
        return str(e)

def save_to_json(data, output_json_path):
    with open(output_json_path, 'w', encoding='utf-8') as json_file:
        json.dump(data, json_file, ensure_ascii=False, indent=4)

def clean_and_chunk_text(text, chunk_size):
    cleaned_text = text.replace('\n', ' ').replace('\"', '"').strip()
    cleaned_text = re.sub(r'\s+', ' ', cleaned_text)
    
    chunks = []
    start = 0
    while start < len(cleaned_text):
        end = start + chunk_size
        if end >= len(cleaned_text):
            chunks.append(cleaned_text[start:])
            break
        else:
            period_index = cleaned_text.rfind('. ', start, end) + 1
            if period_index > start:
                end = period_index
            else:
                if end < len(cleaned_text):
                    end = cleaned_text.find('. ', end) + 1
                if end == 0:  # No more periods found, take the rest of the text
                    end = len(cleaned_text)

            chunk = cleaned_text[start:end].strip()
            chunks.append(chunk)
            start = end

    return chunks       
        
def extract_text_from_pdf(pdf_file_path):
    text = ""
    pdf_document = fitz.open(pdf_file_path)
    for page in pdf_document:
        text += page.get_text()
    pdf_document.close()
    return text

def extract_text_from_word(docx_file_path):
    text = ""
    doc = docx.Document(docx_file_path)
    for para in doc.paragraphs:
        text += para.text + "\n"
    return text

def extract_text_from_csv(csv_file_path):
    df = pd.read_csv(csv_file_path)
    text = df.to_string(index=False)
    return text

def extract_text_from_xlsx(xlsx_file_path):
    workbook = load_workbook(filename=xlsx_file_path)
    sheet = workbook.active
    text = ""
    for row in sheet.iter_rows(values_only=True):
        text += " ".join(map(str, row)) + "\n"
    return text

def extract_text_from_md(md_file_path):
    with open(md_file_path, 'r', encoding='utf-8') as md_file:
        md_content = md_file.read()
        text = markdown2.markdown(md_content)  # Convert Markdown to plain text
        return text
    
def process_file(file_path):
    file_extension = os.path.splitext(file_path)[-1].lower()

    if file_extension == '.pdf':
        text = extract_text_from_pdf(file_path)
    elif file_extension == '.docx':
        text = extract_text_from_word(file_path)
    elif file_extension == '.csv':
        text = extract_text_from_csv(file_path)
    elif file_extension == '.xlsx':
        text = extract_text_from_xlsx(file_path)
    elif file_extension == '.md':
        text = extract_text_from_md(file_path) 
    else:
        raise ValueError(f"Unsupported file format: {file_extension}")

    # Get the directory and base filename of the input file
    file_dir, file_name = os.path.split(file_path)
    # Remove the file extension to create the output JSON file name
    base_name_without_extension = os.path.splitext(file_name)[0]
    # Construct the output JSON file path by appending ".json" to the base name
    output_json_path = os.path.join(file_dir, f"{base_name_without_extension}.json")

    chunks = clean_and_chunk_text(text, CHUNK_SIZE)
    qa_data = []
    for i, chunk in enumerate(chunks[:MAX_QUESTIONS], 1):
        question = generate_question(chunk)
        question = remove_prompt_from_response(question)
        if question:
            answer = generate_answer(chunk, question)
            answer = remove_prompt_from_response(answer)
            if answer:
                qa_data.append({
                    'input': chunk,
                    'instruction': question,
                    'output': answer
                })
    save_to_json(qa_data, output_json_path)

file_path = "/home/cr8dl-user/2920wall/ml_training/2920Wall_concatenated.md"
process_file(file_path)
